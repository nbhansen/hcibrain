# Few-shot examples for abstract analysis
# These examples show how to identify contributions and findings in HCI abstracts

examples:
  - section_text: |
      "We present TouchGestures, a novel interaction technique that enables users to perform complex multi-touch gestures with 40% fewer errors than standard touch interfaces. Through a controlled study with 24 participants, we found that users completed tasks 23% faster using TouchGestures compared to conventional touch input. Our system introduces three new gesture recognition algorithms that improve accuracy while reducing computational overhead by 15%. The results suggest that TouchGestures could significantly enhance mobile interaction design."
    
    expected_extraction:
      elements:
        - element_type: "artifact"
          text: "TouchGestures, a novel interaction technique that enables users to perform complex multi-touch gestures with 40% fewer errors than standard touch interfaces"
          evidence_type: "quantitative"
          confidence: 0.95
          hci_contribution_type: "artifact"
        
        - element_type: "finding"
          text: "users completed tasks 23% faster using TouchGestures compared to conventional touch input"
          evidence_type: "quantitative"
          confidence: 0.95
          hci_contribution_type: "knowledge-increasing"
        
        - element_type: "method"
          text: "three new gesture recognition algorithms that improve accuracy while reducing computational overhead by 15%"
          evidence_type: "quantitative"
          confidence: 0.90
          hci_contribution_type: "method"
        
        - element_type: "claim"
          text: "TouchGestures could significantly enhance mobile interaction design"
          evidence_type: "mixed"
          confidence: 0.80
          hci_contribution_type: "knowledge-increasing"

  - section_text: |
      "Previous research has shown that virtual reality training can improve performance, but existing systems lack adaptive feedback mechanisms. We developed AdaptVR, a training system that dynamically adjusts difficulty based on user performance. In a study with 32 medical students, AdaptVR improved training outcomes by 35% compared to static VR training. Our contribution is a novel adaptive algorithm that personalizes VR experiences in real-time."
    
    expected_extraction:
      elements:
        - element_type: "claim"
          text: "existing systems lack adaptive feedback mechanisms"
          evidence_type: "theoretical"
          confidence: 0.85
          hci_contribution_type: "knowledge-contesting"
        
        - element_type: "artifact"
          text: "AdaptVR, a training system that dynamically adjusts difficulty based on user performance"
          evidence_type: "mixed"
          confidence: 0.95
          hci_contribution_type: "artifact"
        
        - element_type: "finding"
          text: "AdaptVR improved training outcomes by 35% compared to static VR training"
          evidence_type: "quantitative"
          confidence: 0.95
          hci_contribution_type: "knowledge-increasing"
        
        - element_type: "method"
          text: "novel adaptive algorithm that personalizes VR experiences in real-time"
          evidence_type: "theoretical"
          confidence: 0.90
          hci_contribution_type: "method"

  - section_text: |
      "This paper reviews 150 studies on accessibility in mobile applications published between 2015-2023. Our analysis reveals three critical gaps in current accessibility research: limited focus on cognitive disabilities, insufficient evaluation with real users, and lack of cross-platform consistency guidelines. We propose a unified framework for mobile accessibility evaluation that addresses these limitations."
    
    expected_extraction:
      elements:
        - element_type: "finding"
          text: "three critical gaps in current accessibility research: limited focus on cognitive disabilities, insufficient evaluation with real users, and lack of cross-platform consistency guidelines"
          evidence_type: "qualitative"
          confidence: 0.90
          hci_contribution_type: "synthesis"
        
        - element_type: "artifact"
          text: "unified framework for mobile accessibility evaluation that addresses these limitations"
          evidence_type: "theoretical"
          confidence: 0.85
          hci_contribution_type: "theory"

guidance_notes: |
  When analyzing abstracts:
  1. Look for the primary contribution statement - often introduced with phrases like "We present", "Our contribution", "We propose"
  2. Identify empirical findings with specific metrics or performance improvements
  3. Distinguish between novel artifacts/methods and their validation results
  4. Focus on statements that represent knowledge advancement, not background information
  5. Pay attention to comparative claims (better than, faster than, more accurate than)
  6. Look for gap identification in existing research (knowledge-contesting contributions)