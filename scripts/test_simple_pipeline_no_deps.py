#!/usr/bin/env python3
"""
Test the simple extraction pipeline without external dependencies.
"""

import asyncio
import sys
from pathlib import Path

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

async def test_pipeline_components():
    """Test that all pipeline components work together without external deps."""
    print("üöÄ Testing Simple Pipeline Components")
    print("=" * 50)
    
    try:
        # Test individual component imports
        from hci_extractor.pipeline.section_detector import detect_sections
        from hci_extractor.pipeline.section_processor import LLMSectionProcessor
        from hci_extractor.pipeline.simple_validator import validate_extracted_elements
        from hci_extractor.models import PdfContent, PdfPage, Paper, ExtractedElement
        from hci_extractor.llm import LLMProvider
        
        print("‚úÖ All components imported successfully")
        
        # Create test data
        academic_text = """
        Abstract
        
        We present a novel approach to gesture recognition that achieves 94% accuracy.
        
        1. Introduction
        
        Human-computer interaction has evolved significantly. Our research addresses gesture recognition challenges.
        
        2. Methodology
        
        We used a controlled experimental design with 50 participants following standard HCI protocols.
        
        3. Results
        
        Users completed tasks 30% faster with the new interface. Participants rated the system as intuitive.
        """
        
        # Create PDF content
        page = PdfPage(
            page_number=1,
            text=academic_text,
            char_count=len(academic_text),
            dimensions=(612.0, 792.0),
            char_positions=()
        )
        
        pdf_content = PdfContent(
            file_path="test.pdf",
            total_pages=1,
            pages=(page,),
            extraction_metadata={"test": True}
        )
        
        print("‚úÖ Test PDF content created")
        
        # Test section detection
        sections = detect_sections(pdf_content)
        print(f"‚úÖ Section detection: {len(sections)} sections found")
        print(f"   Sections: {[s.section_type for s in sections]}")
        
        # Test paper creation
        paper = Paper.create_with_auto_id(
            title="Test Paper",
            authors=("Dr. Test",),
            venue="Test Conference"
        )
        print("‚úÖ Paper object created")
        
        # Mock LLM provider
        class MockLLMProvider(LLMProvider):
            def __init__(self):
                super().__init__()
                
            async def analyze_section(self, section_text, section_type, context=None):
                return [
                    {
                        "element_type": "finding",
                        "text": "Users completed tasks 30% faster with the new interface",
                        "evidence_type": "quantitative",
                        "confidence": 0.90
                    },
                    {
                        "element_type": "claim",
                        "text": "We present a novel approach to gesture recognition",
                        "evidence_type": "theoretical",
                        "confidence": 0.85
                    }
                ]
            
            def validate_response(self, response):
                return True
                
            async def _make_api_request(self, prompt, **kwargs):
                return {"elements": []}
        
        # Test section processing
        llm_provider = MockLLMProvider()
        processor = LLMSectionProcessor(llm_provider=llm_provider)
        
        if sections:
            section = sections[0]
            elements = await processor.process_section(section, paper)
            print(f"‚úÖ Section processing: {len(elements)} elements extracted")
            
            # Test validation
            validated_elements = validate_extracted_elements(elements, pdf_content)
            print(f"‚úÖ Validation: {len(validated_elements)} elements validated")
            
            # Display results
            for element in validated_elements:
                print(f"   üìÑ {element.element_type}: '{element.text[:50]}...'")
        
        print("\nüéâ All pipeline components working!")
        return True
        
    except Exception as e:
        print(f"‚ùå Pipeline test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_end_to_end_workflow():
    """Test the complete workflow with mocked components."""
    print("\nüß™ Testing End-to-End Workflow...")
    
    try:
        # Create a completely self-contained workflow test
        from hci_extractor.models import Paper, ExtractedElement, ExtractionResult
        
        # Simulate the complete workflow
        print("1Ô∏è‚É£ Creating paper metadata...")
        paper = Paper.create_with_auto_id(
            title="A Novel Approach to Gesture Recognition",
            authors=("Dr. Research", "Prof. Science"),
            venue="CHI 2024",
            year=2024
        )
        
        print("2Ô∏è‚É£ Simulating element extraction...")
        elements = [
            ExtractedElement.create_with_auto_id(
                paper_id=paper.paper_id,
                element_type="claim",
                text="We present a novel approach to gesture recognition that improves accuracy",
                section="abstract",
                confidence=0.90,
                evidence_type="theoretical",
                page_number=1
            ),
            ExtractedElement.create_with_auto_id(
                paper_id=paper.paper_id,
                element_type="finding",
                text="Our system achieves 94% accuracy compared to 85% baseline",
                section="results",
                confidence=0.95,
                evidence_type="quantitative",
                page_number=3
            ),
            ExtractedElement.create_with_auto_id(
                paper_id=paper.paper_id,
                element_type="method",
                text="We used a controlled experimental design with 50 participants",
                section="methodology",
                confidence=0.85,
                evidence_type="mixed",
                page_number=2
            )
        ]
        
        print("3Ô∏è‚É£ Creating extraction result...")
        result = ExtractionResult(
            paper=paper,
            elements=tuple(elements),
            extraction_metadata={
                "sections_found": 4,
                "elements_extracted": len(elements),
                "processing_status": "success"
            }
        )
        
        # Verify the result
        print(f"‚úÖ Extraction complete!")
        print(f"   üìã Paper: {result.paper.title}")
        print(f"   üë• Authors: {', '.join(result.paper.authors)}")
        print(f"   üîç Elements: {len(result.elements)}")
        
        # Check element distribution
        element_types = {}
        for element in result.elements:
            element_types[element.element_type] = element_types.get(element.element_type, 0) + 1
        
        print(f"   üìä Types: {element_types}")
        
        # Test immutability
        try:
            result.paper.title = "Modified"
            print("‚ùå Immutability test failed")
            return False
        except (AttributeError, TypeError):
            print("‚úÖ Results are immutable")
        
        # Test data integrity
        for element in result.elements:
            assert element.paper_id == paper.paper_id
            assert 0.0 <= element.confidence <= 1.0
            assert element.text.strip()
            assert element.section
        
        print("‚úÖ Data integrity verified")
        print("üéâ End-to-end workflow successful!")
        return True
        
    except Exception as e:
        print(f"‚ùå Workflow test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """Run all tests."""
    
    tests_passed = 0
    total_tests = 2
    
    if await test_pipeline_components():
        tests_passed += 1
        print("‚úÖ Pipeline components PASSED")
    else:
        print("‚ùå Pipeline components FAILED")
    
    if await test_end_to_end_workflow():
        tests_passed += 1
        print("‚úÖ End-to-end workflow PASSED")  
    else:
        print("‚ùå End-to-end workflow FAILED")
    
    print("\n" + "=" * 50)
    print(f"üìä Results: {tests_passed}/{total_tests} tests passed")
    
    if tests_passed == total_tests:
        print("üéâ Simple extraction pipeline is ready!")
        print("\nüöÄ The simplest possible version is working!")
        print("\nüìù You can now:")
        print("   ‚Ä¢ Extract sections from academic papers")
        print("   ‚Ä¢ Process sections with any LLM provider")
        print("   ‚Ä¢ Get back classified text snippets")
        print("   ‚Ä¢ Apply basic validation (optional)")
        print("   ‚Ä¢ Everything is immutable and thread-safe")
        return True
    else:
        print("üí• Some tests failed!")
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)